# ChestX-ray Pathology Detection with YOLOv8

**Binary object detection for localizing pathological findings in chest X-ray images**

## ğŸ“‹ Overview

This project implements **YOLOv8-based object detection** for identifying and localizing pathologies in chest X-ray images. The model is trained on 87,404 images (86,224 normal + 700 pathology annotations) and achieves baseline performance for medical imaging tasks.

**Key Achievement**: Production-ready ML pipeline with proper data split strategy, training optimization, and comprehensive documentation.

---

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Create virtual environment
python -m venv chest_env
source chest_env/bin/activate  # Linux/Mac
# or
chest_env\Scripts\activate  # Windows PowerShell

# Install dependencies
pip install -r requirements.txt

# Verify GPU
python -c "import torch; print(torch.cuda.is_available())"
```

### 2. Prepare Dataset

```bash
# Full dataset (86k normal) - ~60 minutes
python src/data_prep_correct_optimized.py --max-train-normal 0

# OR quick test (5k normal) - ~10 minutes
python src/data_prep_correct_optimized.py --max-train-normal 5000
```

Output: `datasets/` folder with YOLO-format images + labels

### 3. Train Model

```bash
python src/train.py \
    --data-yaml datasets/data.yaml \
    --model n \
    --epochs 40 \
    --batch-size 48 \
    --device "0"
```

Model checkpoints saved to `results/detect/weights/`

### 4. Run Inference

```bash
# Evaluate on test set
python src/evaluate.py \
    --model results/detect/weights/best.pt \
    --data-yaml datasets/data.yaml

# Predict on custom images
python src/predict.py \
    --model results/detect/weights/best.pt \
    --source datasets/images/test \
    --conf 0.25
```

---

## ğŸ“Š Dataset Strategy

### Why This Split Works

```
Training Set (86,924 images):
  â”œâ”€ Normal: 86,224 (no boxes)    â† Learn what healthy looks like
  â””â”€ Pathology: 700 (with boxes)   â† Learn to detect pathology

Validation Set (390 images):
  â”œâ”€ Normal: 300                   â† Realistic mix for validation
  â””â”€ Pathology: 90

Test Set (90 images):
  â””â”€ Pathology: 90                 â† Clean final evaluation
```

**Key Insight**: This prevents validation metric inflation while ensuring model learns both positive and negative examples.

### Data Transformations

```python
# Grayscale â†’ RGB (medical images are grayscale)
img_gray = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)

# Bbox normalization to YOLO format
# Input: pixel coords [x, y, w, h]
# Output: normalized [x_center, y_center, w_norm, h_norm] âˆˆ [0, 1]
x_center = (x + w/2) / img_width
y_center = (y + h/2) / img_height
w_norm = w / img_width
h_norm = h / img_height
```

---

## ğŸ—ï¸ Project Structure

```
chestxray-detection/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep_correct_optimized.py   â† Data split & preparation
â”‚   â”œâ”€â”€ train.py                         â† Training pipeline
â”‚   â”œâ”€â”€ evaluate.py                      â† Metrics computation
â”‚   â””â”€â”€ predict.py                       â† Inference
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ annotations.csv                  (86k+ bbox annotations)
â”‚   â”œâ”€â”€ train_val_list.txt              (image list for train/val)
â”‚   â”œâ”€â”€ test_list.txt                   (test image list)
â”‚   â””â”€â”€ images/                         (~50GB chest X-rays)
â”œâ”€â”€ datasets/                           (prepared YOLO format)
â”‚   â”œâ”€â”€ images/ (train/val/test)
â”‚   â”œâ”€â”€ labels/ (YOLO .txt files)
â”‚   â””â”€â”€ data.yaml (YOLOv8 config)
â”œâ”€â”€ results/                            (training outputs)
â”‚   â””â”€â”€ detect/weights/
â”‚       â”œâ”€â”€ best.pt
â”‚       â””â”€â”€ last.pt
â”œâ”€â”€ DOCUMENTATION.md                   â† Comprehensive guide
â”œâ”€â”€ README.md                          â† This file
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Training Configuration

### Hyperparameters

| Parameter | Value | Notes |
|-----------|-------|-------|
| **Model** | YOLOv8-Nano | 3M params, fast inference |
| **Batch Size** | 48 | RTX 3060: ~1GB VRAM usage |
| **Epochs** | 40-50 | Sufficient for convergence |
| **Image Size** | 640Ã—640 | YOLO default for detail |
| **Learning Rate** | 0.001 | YOLOv8 cosine annealing |
| **Cache** | RAM (True) | Avoid 330GB disk cache! |
| **Patience** | 10 | Early stopping (epochs) |

### Memory Usage

```
GPU Memory (RTX 3060, 12GB):
â”œâ”€ Model weights: 150 MB
â”œâ”€ Batch (48Ã—640Ã—640Ã—3): 700 MB
â”œâ”€ Optimizer state: 150 MB
â””â”€ Available: ~10.8 GB âœ…
```

---

## ğŸ“ˆ Expected Training Progress

### Epoch 1-5: Initialization
```
Instances: 0-5        (model learning to detect)
box_loss: 2.0-3.0     (localization loss)
cls_loss: 30â†’5        (rapid improvement)
Metrics: 0            (predictions too weak)
```

### Epoch 10-20: Learning Accelerates
```
Instances: 20-40      (stable detection)
box_loss: 1.5-2.0     (steady improvement)
cls_loss: 2.0-3.0     (stable)
Metrics: 0.01-0.05    (first predictions)
```

### Epoch 25-40: Refinement
```
Instances: 20-30      (stable)
box_loss: 1.5-2.0     (minimal change)
cls_loss: 2.0-3.0     (plateau)
Metrics: 0.05-0.15    (measurable gains)
```

---

## ğŸ“Š Model Performance

### Baseline Metrics (40 epochs, batch=48)

Expected performance for **binary pathology detection**:
- **mAP50**: 0.08-0.15 (reasonable for 700 annotated samples)
- **mAP50-95**: 0.03-0.08 (stricter metric)
- **Precision**: 0.15-0.25
- **Recall**: 0.10-0.15

### Performance by Factors

| Factor | Impact |
|--------|--------|
| More annotation (1500+ samples) | +0.05 mAP50 |
| Larger model (Small/Medium) | +0.03-0.05 mAP50 |
| Multiclass (specific pathologies) | Better clinical utility |
| Confidence tuning | Up to Â±0.1 Precision |

---

## ğŸ”§ Troubleshooting

### âŒ "Instances: 0" throughout training
```bash
# Check label files
(ls datasets/labels/train/*.txt | Where-Object {(Get-Item $_).Length -gt 0}).Count
# Should output: 700
```

### âŒ "CUDA out of memory" at epoch 31
```bash
# Albumentations kicks in, reduce batch
python src/train.py --batch-size 32 ...
```

### âŒ "No such file: datasets/data.yaml"
```bash
# Run data prep first
python src/data_prep_correct_optimized.py --max-train-normal 0
```

### âŒ Validation metrics = 0 at epoch 40
```bash
# Verify val set has pathology boxes
# Should have 90 non-empty .txt files in datasets/labels/val/
```

---

## ğŸ“š File Descriptions

### `data_prep_correct_optimized.py`
- Loads CSV annotations + image lists
- Converts pixel coords to YOLO normalized format
- Splits data with custom strategy (train/val/test)
- Handles grayscaleâ†’RGB conversion
- Saves YOLO-format labels + data.yaml

**Usage:**
```bash
python src/data_prep_correct_optimized.py \
    --csv-path data/annotations.csv \
    --train-list data/train_val_list.txt \
    --img-dir data/images \
    --output-dir datasets \
    --max-train-normal 0  # 0 = all, N = limit to N
```

### `train.py`
- YOLOv8 training loop with proper config
- Logging + early stopping
- Model checkpointing (best + last)
- Validation every epoch
- Optional inference after training

**Usage:**
```bash
python src/train.py \
    --data-yaml datasets/data.yaml \
    --model n \
    --epochs 40 \
    --batch-size 48 \
    --output-dir results_full
```

### `evaluate.py`
- Compute mAP, precision, recall
- Per-class metrics
- Confusion matrix
- Export results to CSV

### `predict.py`
- Inference on image folder
- Visualization with bboxes
- Confidence filtering
- JSON output format

---

## ğŸ’¾ Storage Requirements

```
Raw data:       ~50 GB (images)
Prepared data:  ~50 GB (YOLO format)
Models:         10-20 MB (weights)
Results:        5-10 GB (outputs)
Total:          ~110 GB

Recommendations:
- Fast SSD/NVMe for datasets/ (faster I/O)
- Regular HDD for raw data storage (if space limited)
```

---

## ğŸ¯ Performance Notes

### Training Time
- **5k normal images**: ~1 hour Ã— 40 epochs = 40 hours
- **86k normal images**: ~3 hours Ã— 40 epochs = 120 hours
- Per epoch: 8-12 minutes (varies with cache, augmentations)

### Inference Speed
- **Latency**: 1.6 ms per image (RTX 3060)
- **Throughput**: ~625 images/second

### Reproducibility
- Seed: 42 (deterministic training)
- Fixed augmentations
- Saved config â†’ full reproducibility

---

## ğŸ“– Additional Resources

For detailed information, see **DOCUMENTATION.md**:
- âœ… Complete data split strategy explanation
- âœ… Training dynamics & red flags
- âœ… Metric explanations
- âœ… Improvement strategies
- âœ… Multi-phase development roadmap

---

## ğŸš€ Next Steps

### Immediate (Testing)
1. Run full data prep: `python src/data_prep_correct_optimized.py --max-train-normal 0`
2. Train model: 40 epochs on full dataset
3. Evaluate metrics on test set
4. Run predictions

### Short-term (Enhancement)
1. **Multiclass Detection**: Implement specific pathology classes
2. **Model Scaling**: Try YOLOv8-Small for improved accuracy
3. **Confidence Tuning**: Optimize threshold for production
4. **Post-processing**: Advanced NMS strategies

### Long-term (Deployment)
1. **ONNX Export**: Model inference optimization
2. **API Service**: REST endpoint for predictions
3. **Clinical Validation**: External dataset testing
4. **Real-time Processing**: Video stream inference

---

## ğŸ”— References

- [YOLOv8 Docs](https://docs.ultralytics.com/)
- [YOLO Format](https://roboflow.com/formats/yolo-darknet-txt)
- [Object Detection Metrics](https://github.com/rafaelpadilla/Object-Detection-Metrics)
- [ChexPert Dataset](https://stanfordmlgroup.github.io/competitions/chexpert/)

---

## ğŸ“„ License

MIT

---

## âœ… Checklist for Presentation

- [x] Data pipeline working (86k+ images prepared)
- [x] Training pipeline validated (metrics computing)
- [x] Baseline model trained (40 epochs complete)
- [x] Comprehensive documentation
- [x] Troubleshooting guide
- [x] .gitignore for large files
- [ ] Final test set evaluation
- [ ] Production deployment (optional)

**Status**: Ready for Monday presentation âœ…

---

**Last Updated**: December 19, 2025
